from math import sqrt
import pandas as pd
import numpy as np
import scipy.spatial as sp


def train_to_df(file, col_num):
    df = pd.read_csv(file, header=None, names=range(col_num), delim_whitespace=True)
    return df


def test_to_df(file, col_num):
    df = pd.read_csv(file, header=None, names=range(col_num), sep=",")
    return df


def label_to_ls(file, col_num):
    # df = pd.read_csv(file, header=None, delim_whitespace=True)
    with open(file, "r") as f:
        s = f.read()
        lst = s.split("\n")
        if "" in lst:
            lst.remove("")
        lst = [int(lst[n]) for n in range(len(lst) - 1)]

    return lst


def knn(my_row, sample, x, k, na_ls):
    distance = []
    avgs = {}
    k_near = 0
    for s in sample.index:
        dist = np.linalg.norm(my_row.values - sample.loc[[s]].values)

        distance.append(dist)

    part = np.argpartition(distance, k)
    idx = sample.index[part[:k]]

    for n in na_ls:
        if n not in avgs.keys():
            sum = 0
            for i in idx:
                sum += df[n][i]
            avg = sum / (sample.shape[0])

            avgs[n] = avg
    return avgs


def find_missing(my_df):
    new_df = my_df.copy()

    s = new_df.stack(dropna=False)
    d = {}
    for x in s.index[s.isna()]:
        a = list(x)

        if a[0] not in d.keys():
            d[a[0]] = []
        d[a[0]].append(a[1])

    return d


def prep_for_knn(d, test_file, k, out_file):
    results = df.copy()
    size = len(d)
    for x in range(size):
        ls = d[x]
        new_df = df.dropna(axis="rows", subset=ls)

        new_df = new_df.fillna(new_df.mean())
        new_df = new_df.drop(columns=ls, axis="columns")
        my_row = df.loc[[x]]
        my_row = my_row.drop(columns=ls, axis="columns")

        avgs = knn(my_row, new_df, x, k, ls)
        for key in avgs:
            results[key][x] = avgs.get(key)
    results.to_csv(
        f"missing-values-filled/{out_file}.txt",
        header=None,
        index=None,
        sep="\t",
    )
    print("outputted")


def classify(train, test, classes, k, out_file):
    size = len(test)
    o = set(classes)
    closest = dict.fromkeys(o, 0)
    result = []
    for x in range(size):
        distance = []
        avgs = {}
        k_near = 0
        my_row = train.loc[[x]]
        for s in train.index:
            print([my_row.values, train.loc[[s]].values])

            dist = np.nansum((my_row.values - train.loc[[s]].values) ** 2)
            distance.append(dist)

        part = np.argpartition(distance, k)
        idx = train.index[part[:k]]

        for i in idx:
            closest[classes[i]] += 1
            max_value = max(closest, key=closest.get)
        result.append(max)

    with open(out_file, "w") as f:
        for line in result:
            f.write(str(result))
    print("outputted")
    return None


train_files = [f"data/TrainData{n}.txt" for n in range(1, 7)]
test_files = [f"data/TestData{n}.txt" for n in range(1, 7)]
train_label = [f"data/TrainLabel{n}.txt" for n in range(1, 7)]
out_files = [f"class_out{i}" for i in range(1, 7)]

feat_nums = [3312, 9182, 12, 112, 11, 142]
sample_nums = [150, 100, 6300, 2547, 1119, 612]

for index in range(7):
    print(train_files[index])

    train = train_to_df(train_files[index], feat_nums[index])
    test = test_to_df(train_files[index], feat_nums[index])
    train = train.replace(1e99, np.nan)
    test = test_to_df(test_files[index], feat_nums[index])
    label = label_to_ls(train_label[index], feat_nums[index])
    classify(train, test, label, 3, out_files[index])
